{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "final_data = pd.read_excel('Final_Claims_Data_with_AggregatesV2.xlsx', dtype={'Policy': str, 'Unit': str})\n",
    "insurance_data = pd.read_csv('Transformed_Auto_Insurance_Cleaned_For_GLM_V2.csv', encoding='utf-8-sig', dtype={'Policy': str, 'Unit': str})\n",
    "\n",
    "# Deduplication\n",
    "print(\"\\U0001f9f9 Removing duplicate insurance rows...\")\n",
    "insurance_data = insurance_data.drop_duplicates()\n",
    "insurance_data = insurance_data.drop_duplicates(subset=['Policy', 'Unit', 'Start_Date', 'End_Date'])\n",
    "insurance_data = insurance_data[insurance_data['PrimaSuscrita'] > 0]\n",
    "insurance_data.to_csv('InsuranceData_Filtered_Deduplicated.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Convert dates\n",
    "print(\"\\ud83d\\uddd3\\ufe0f Converting date fields...\")\n",
    "final_data['Start_Date'] = pd.to_datetime(final_data['Start_Date'], errors='coerce')\n",
    "final_data['Occurrence_date'] = pd.to_datetime(final_data['Occurrence_date'], errors='coerce')\n",
    "insurance_data['Start_Date'] = pd.to_datetime(insurance_data['Start_Date'], errors='coerce')\n",
    "insurance_data['End_Date'] = pd.to_datetime(insurance_data['End_Date'], errors='coerce')\n",
    "\n",
    "# Create Key\n",
    "final_data['Key'] = final_data['Policy'] + '_' + final_data['Unit']\n",
    "insurance_data['Key'] = insurance_data['Policy'] + '_' + insurance_data['Unit']\n",
    "\n",
    "# Format insurance_data\n",
    "print(\"\\ud83e\\uddfc Formatting insurance_data...\")\n",
    "for col in tqdm(insurance_data.columns, desc=\"Formatting insurance_data\"):\n",
    "    if insurance_data[col].dtype == \"object\":\n",
    "        insurance_data[col] = insurance_data[col].fillna(\"\").astype(str)\n",
    "    elif pd.api.types.is_numeric_dtype(insurance_data[col]):\n",
    "        insurance_data[col] = pd.to_numeric(insurance_data[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Unique index for claims\n",
    "final_data = final_data.reset_index().rename(columns={'index': 'Claim_Row_ID'})\n",
    "\n",
    "# Filter insurance keys found in claims\n",
    "print(\"\\ud83d\\udd0e Filtering relevant policy-units...\")\n",
    "matching_keys = final_data['Key'].unique()\n",
    "filtered_insurance_data = insurance_data[insurance_data['Key'].isin(matching_keys)]\n",
    "non_matching_rows = insurance_data[~insurance_data['Key'].isin(matching_keys)]\n",
    "\n",
    "# 1-to-many Matching\n",
    "aggregated_results = []\n",
    "used_claim_ids = set()\n",
    "used_insurance_indices = set()\n",
    "unmatched_claims = []\n",
    "\n",
    "print(\"\\ud83d\\udccc Matching claims to insurance rows (all that match)...\")\n",
    "for idx, ins_row in tqdm(filtered_insurance_data.iterrows(), total=len(filtered_insurance_data), desc=\"Matching multiple claims\"):\n",
    "    if idx in used_insurance_indices:\n",
    "        continue\n",
    "\n",
    "    policy_unit_key = ins_row['Key']\n",
    "    start_date = ins_row['Start_Date']\n",
    "    end_date = ins_row['End_Date']\n",
    "\n",
    "    potential_claims = final_data[\n",
    "        (final_data['Key'] == policy_unit_key) &\n",
    "        (~final_data['Claim_Row_ID'].isin(used_claim_ids))\n",
    "    ]\n",
    "\n",
    "    if potential_claims.empty:\n",
    "        unmatched_claims.append({**ins_row[['Policy', 'Unit', 'Start_Date', 'End_Date']].to_dict(),\n",
    "                                 'Reason': 'No available unmatched claims for this Policy-Unit'})\n",
    "        continue\n",
    "\n",
    "    matching_claims = potential_claims[potential_claims['Start_Date'] == start_date]\n",
    "\n",
    "    if matching_claims.empty:\n",
    "        matching_claims = potential_claims[\n",
    "            (potential_claims['Occurrence_date'] >= start_date) &\n",
    "            (potential_claims['Occurrence_date'] <= end_date)\n",
    "        ]\n",
    "\n",
    "    if matching_claims.empty:\n",
    "        matching_claims = potential_claims[\n",
    "            (potential_claims['Occurrence_date'] >= start_date - timedelta(days=365)) &\n",
    "            (potential_claims['Occurrence_date'] <= end_date + timedelta(days=365))\n",
    "        ]\n",
    "\n",
    "    if not matching_claims.empty:\n",
    "        selected_claim = matching_claims.copy()\n",
    "        used_claim_ids.update(selected_claim['Claim_Row_ID'].values)\n",
    "        used_insurance_indices.add(idx)\n",
    "\n",
    "        aggregated_data = selected_claim.groupby(['Policy', 'Unit', 'Coverage_Type']).agg({\n",
    "            'Payed_Amount': 'sum',\n",
    "            'Last_Pending_Amount': 'sum',\n",
    "            'Incurred': 'sum',\n",
    "            'Claim_Number': pd.Series.nunique\n",
    "        }).reset_index()\n",
    "\n",
    "        aggregated_data['Policy'] = ins_row['Policy']\n",
    "        aggregated_data['Unit'] = ins_row['Unit']\n",
    "        aggregated_data['Start_Date'] = start_date\n",
    "        aggregated_data['End_Date'] = end_date\n",
    "        aggregated_data['Insurance_Row_Index'] = idx\n",
    "\n",
    "        aggregated_results.append(aggregated_data)\n",
    "    else:\n",
    "        unmatched_claims.append({**ins_row[['Policy', 'Unit', 'Start_Date', 'End_Date']].to_dict(),\n",
    "                                 'Reason': 'No claim matched this period'})\n",
    "\n",
    "# Aggregation and export\n",
    "if aggregated_results:\n",
    "    print(\"\\ud83d\\udcca Aggregating results...\")\n",
    "    aggregated_df = pd.concat(aggregated_results)\n",
    "    pivot_df = aggregated_df.pivot_table(\n",
    "        index='Insurance_Row_Index',\n",
    "        columns='Coverage_Type',\n",
    "        values=['Payed_Amount', 'Last_Pending_Amount', 'Incurred', 'Claim_Number'],\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0)\n",
    "    pivot_df.columns = ['_'.join(col).strip() for col in pivot_df.columns.values]\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    insurance_data = insurance_data.reset_index().rename(columns={'index': 'Insurance_Row_Index'})\n",
    "    final_result = insurance_data.merge(pivot_df, on='Insurance_Row_Index', how='left')\n",
    "\n",
    "    value_cols = [col for col in final_result.columns if col.startswith(('Claim_Number_', 'Payed_Amount_', 'Last_Pending_Amount_', 'Incurred_'))]\n",
    "    final_result[value_cols] = final_result[value_cols].fillna(0)\n",
    "\n",
    "    final_result['Total_Claim_Count'] = final_result.filter(like='Claim_Number_').sum(axis=1)\n",
    "    final_result['Total_Payed_Amount'] = final_result.filter(like='Payed_Amount_').sum(axis=1)\n",
    "    final_result['Total_Pending_Amount'] = final_result.filter(like='Last_Pending_Amount_').sum(axis=1)\n",
    "    final_result['Total_Incurred_Amount'] = final_result.filter(like='Incurred_').sum(axis=1)\n",
    "\n",
    "    final_result.drop(columns=['Insurance_Row_Index', 'Key', 'Cliente'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Unit Count per Policy-Year\n",
    "    print(\"\\ud83d\\udd39 Calculating Unit_Count_Per_Policy_Year...\")\n",
    "    final_result['Start_Year'] = pd.to_datetime(final_result['Start_Date']).dt.year\n",
    "    unit_counts = final_result.groupby(['Policy', 'Start_Year'])['Unit'].nunique().reset_index()\n",
    "    unit_counts = unit_counts.rename(columns={'Unit': 'Unit_Count_Per_Policy_Year'})\n",
    "    final_result = final_result.merge(unit_counts, on=['Policy', 'Start_Year'], how='left')\n",
    "\n",
    "    # Historical metrics\n",
    "    print(\"\\ud83d\\udcca Calculating historical metrics...\")\n",
    "    final_result['PU_Key'] = final_result['Policy'] + '_' + final_result['Unit']\n",
    "    with_claims = final_result[(final_result['Total_Claim_Count'] > 0) | (final_result['Total_Incurred_Amount'] > 0)]\n",
    "    claim_count_results = []\n",
    "\n",
    "    grouped = with_claims.groupby('PU_Key')\n",
    "    for key, group in tqdm(grouped, desc=\"Historical calculations\", total=len(grouped)):\n",
    "        group = group.sort_values('Start_Date')\n",
    "        hist_claims = []\n",
    "        hist_ratios = []\n",
    "        for i in range(len(group)):\n",
    "            past = group[group['Start_Date'] < group.iloc[i]['Start_Date']]\n",
    "            hist_claims.append(past['Total_Claim_Count'].sum())\n",
    "            premium = past['PrimaSuscrita'].sum()\n",
    "            incurred = past['Total_Incurred_Amount'].sum()\n",
    "            hist_ratios.append(incurred / premium if premium else None)\n",
    "        group['Historical_Claim_Count'] = hist_claims\n",
    "        group['Historical_Loss_Ratio'] = hist_ratios\n",
    "        claim_count_results.append(group)\n",
    "\n",
    "    enriched = pd.concat(claim_count_results, ignore_index=True)\n",
    "    enriched['Current_Loss_Ratio'] = enriched['Total_Incurred_Amount'] / enriched['PrimaSuscrita']\n",
    "\n",
    "    final_result = final_result.drop(columns=['PU_Key'], errors='ignore')\n",
    "    final_result = final_result.merge(\n",
    "        enriched[['Policy', 'Unit', 'Start_Date', 'Historical_Claim_Count', 'Historical_Loss_Ratio', 'Current_Loss_Ratio']],\n",
    "        on=['Policy', 'Unit', 'Start_Date'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    print(\"\\ud83e\\uddfc Final formatting for export...\")\n",
    "    for col in tqdm(final_result.columns, desc=\"Final format\"):\n",
    "        if final_result[col].dtype == \"object\":\n",
    "            final_result[col] = final_result[col].fillna(\"\").astype(str)\n",
    "        elif pd.api.types.is_numeric_dtype(final_result[col]):\n",
    "            final_result[col] = pd.to_numeric(final_result[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Export\n",
    "    print(\"\\ud83d\\udcc5 Exporting final results...\")\n",
    "    final_result.to_csv('Insurance_1to1_Merged_With_Loss_Ratio.csv', index=False, encoding='utf-8-sig')\n",
    "    final_result.to_parquet(\"Insurance_1to1_Merged_With_Loss_Ratio.parquet\", index=False)\n",
    "    with pd.ExcelWriter(\"Insurance_1to1_Merged_With_Loss_Ratio.xlsx\", engine='xlsxwriter', datetime_format='yyyy-mm-dd') as writer:\n",
    "        final_result.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "    # Optional: Remove accents\n",
    "    def remove_accents(text):\n",
    "        if isinstance(text, str):\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "            text = text.replace('Ã±', 'n').replace('Ã‘', 'N')\n",
    "        return text\n",
    "\n",
    "    print(\"\\ud83c\\udf10 Removing accents from string columns...\")\n",
    "    for col in tqdm(final_result.columns, desc=\"Removing accents\"):\n",
    "        if final_result[col].dtype == \"object\":\n",
    "            final_result[col] = final_result[col].apply(remove_accents)\n",
    "\n",
    "    final_result.to_csv('Insurance_1to1_Merged_With_Loss_Ratio_CleanText.csv', index=False, encoding='utf-8-sig')\n",
    "else:\n",
    "    final_result = pd.DataFrame()\n",
    "    print(\"\\u26a0\\ufe0f No matched claims found.\")\n",
    "\n",
    "# Export unmatched claims\n",
    "unmatched_all = unmatched_claims + [\n",
    "    {\n",
    "        'Policy': row['Policy'],\n",
    "        'Unit': row['Unit'],\n",
    "        'Start_Date': row['Start_Date'],\n",
    "        'End_Date': row['End_Date'],\n",
    "        'Reason': 'Policy-Unit not found in claims data'\n",
    "    }\n",
    "    for _, row in non_matching_rows.iterrows()\n",
    "]\n",
    "if unmatched_all:\n",
    "    unmatched_df = pd.DataFrame(unmatched_all)\n",
    "    unmatched_df.to_csv('Unmatched_Claims_Final.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\u26a0\\ufe0f Exported {len(unmatched_df)} unmatched entries.\")\n",
    "else:\n",
    "    print(\"\\u2705 All insurance rows matched successfully.\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\\ud83d\\udcb0 Total Incurred Matched: {final_result['Total_Incurred_Amount'].sum():,.2f}\")\n",
    "print(f\"\\ud83d\\udd52 Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c5153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramonbatista/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/12yv_3h95dg19ffkc2pk_ffm0000gn/T/ipykernel_4740/3312236332.py:11: DtypeWarning: Columns (23,24,25,26,27,28,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  insurance_data = pd.read_csv('Transformed_Auto_Insurance_Cleaned_For_GLM_V2.csv', encoding='utf-8-sig', dtype={'Policy': str, 'Unit': str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Removing duplicate insurance rows...\n",
      "ðŸ“… Converting date fields...\n",
      "ðŸ§¼ Formatting insurance_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting insurance_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:02<00:00, 36.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Filtering relevant policy-units...\n",
      "ðŸ“Œ Matching claims to insurance rows (all that match)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching multiple claims:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 138434/191127 [28:41<13:31, 64.95it/s]  "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "final_data = pd.read_excel('Final_Claims_Data_with_AggregatesV2.xlsx', dtype={'Policy': str, 'Unit': str})\n",
    "insurance_data = pd.read_csv('Transformed_Auto_Insurance_Cleaned_For_GLM_V2.csv', encoding='utf-8-sig', dtype={'Policy': str, 'Unit': str})\n",
    "\n",
    "# Deduplication\n",
    "print(\"ðŸ§¹ Removing duplicate insurance rows...\")\n",
    "insurance_data = insurance_data.drop_duplicates()\n",
    "insurance_data = insurance_data.drop_duplicates(subset=['Policy', 'Unit', 'Start_Date', 'End_Date'])\n",
    "insurance_data = insurance_data[insurance_data['PrimaSuscrita'] > 0]\n",
    "insurance_data.to_csv('InsuranceData_Filtered_Deduplicated.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Convert dates\n",
    "print(\"ðŸ“… Converting date fields...\")\n",
    "final_data['Start_Date'] = pd.to_datetime(final_data['Start_Date'], errors='coerce')\n",
    "final_data['Occurrence_date'] = pd.to_datetime(final_data['Occurrence_date'], errors='coerce')\n",
    "insurance_data['Start_Date'] = pd.to_datetime(insurance_data['Start_Date'], errors='coerce')\n",
    "insurance_data['End_Date'] = pd.to_datetime(insurance_data['End_Date'], errors='coerce')\n",
    "\n",
    "# Create Key\n",
    "final_data['Key'] = final_data['Policy'] + '_' + final_data['Unit']\n",
    "insurance_data['Key'] = insurance_data['Policy'] + '_' + insurance_data['Unit']\n",
    "\n",
    "# Format insurance_data\n",
    "print(\"ðŸ§¼ Formatting insurance_data...\")\n",
    "for col in tqdm(insurance_data.columns, desc=\"Formatting insurance_data\"):\n",
    "    if insurance_data[col].dtype == \"object\":\n",
    "        insurance_data[col] = insurance_data[col].fillna(\"\").astype(str)\n",
    "    elif pd.api.types.is_numeric_dtype(insurance_data[col]):\n",
    "        insurance_data[col] = pd.to_numeric(insurance_data[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Unique index for claims\n",
    "final_data = final_data.reset_index().rename(columns={'index': 'Claim_Row_ID'})\n",
    "\n",
    "# Filter insurance keys found in claims\n",
    "print(\"ðŸ”Ž Filtering relevant policy-units...\")\n",
    "matching_keys = final_data['Key'].unique()\n",
    "filtered_insurance_data = insurance_data[insurance_data['Key'].isin(matching_keys)]\n",
    "non_matching_rows = insurance_data[~insurance_data['Key'].isin(matching_keys)]\n",
    "\n",
    "# 1-to-many Matching\n",
    "aggregated_results = []\n",
    "used_claim_ids = set()\n",
    "used_insurance_indices = set()\n",
    "unmatched_claims = []\n",
    "\n",
    "print(\"ðŸ“Œ Matching claims to insurance rows (all that match)...\")\n",
    "for idx, ins_row in tqdm(filtered_insurance_data.iterrows(), total=len(filtered_insurance_data), desc=\"Matching multiple claims\"):\n",
    "    if idx in used_insurance_indices:\n",
    "        continue\n",
    "\n",
    "    policy_unit_key = ins_row['Key']\n",
    "    start_date = ins_row['Start_Date']\n",
    "    end_date = ins_row['End_Date']\n",
    "\n",
    "    potential_claims = final_data[\n",
    "        (final_data['Key'] == policy_unit_key) &\n",
    "        (~final_data['Claim_Row_ID'].isin(used_claim_ids))\n",
    "    ]\n",
    "\n",
    "    if potential_claims.empty:\n",
    "        unmatched_claims.append({**ins_row[['Policy', 'Unit', 'Start_Date', 'End_Date']].to_dict(),\n",
    "                                 'Reason': 'No available unmatched claims for this Policy-Unit'})\n",
    "        continue\n",
    "\n",
    "    matching_claims = potential_claims[potential_claims['Start_Date'] == start_date]\n",
    "\n",
    "    if matching_claims.empty:\n",
    "        matching_claims = potential_claims[\n",
    "            (potential_claims['Occurrence_date'] >= start_date) &\n",
    "            (potential_claims['Occurrence_date'] <= end_date)\n",
    "        ]\n",
    "\n",
    "    if matching_claims.empty:\n",
    "        matching_claims = potential_claims[\n",
    "            (potential_claims['Occurrence_date'] >= start_date - timedelta(days=365)) &\n",
    "            (potential_claims['Occurrence_date'] <= end_date + timedelta(days=365))\n",
    "        ]\n",
    "\n",
    "    if not matching_claims.empty:\n",
    "        selected_claim = matching_claims.copy()\n",
    "        used_claim_ids.update(selected_claim['Claim_Row_ID'].values)\n",
    "        used_insurance_indices.add(idx)\n",
    "\n",
    "        aggregated_data = selected_claim.groupby(['Policy', 'Unit', 'Coverage_Type']).agg({\n",
    "            'Payed_Amount': 'sum',\n",
    "            'Last_Pending_Amount': 'sum',\n",
    "            'Incurred': 'sum',\n",
    "            'Claim_Number': pd.Series.nunique\n",
    "        }).reset_index()\n",
    "\n",
    "        aggregated_data['Policy'] = ins_row['Policy']\n",
    "        aggregated_data['Unit'] = ins_row['Unit']\n",
    "        aggregated_data['Start_Date'] = start_date\n",
    "        aggregated_data['End_Date'] = end_date\n",
    "        aggregated_data['Insurance_Row_Index'] = idx\n",
    "\n",
    "        aggregated_results.append(aggregated_data)\n",
    "    else:\n",
    "        unmatched_claims.append({**ins_row[['Policy', 'Unit', 'Start_Date', 'End_Date']].to_dict(),\n",
    "                                 'Reason': 'No claim matched this period'})\n",
    "\n",
    "# Aggregation and export\n",
    "if aggregated_results:\n",
    "    print(\"ðŸ“Š Aggregating results...\")\n",
    "    aggregated_df = pd.concat(aggregated_results)\n",
    "    pivot_df = aggregated_df.pivot_table(\n",
    "        index='Insurance_Row_Index',\n",
    "        columns='Coverage_Type',\n",
    "        values=['Payed_Amount', 'Last_Pending_Amount', 'Incurred', 'Claim_Number'],\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0)\n",
    "    pivot_df.columns = ['_'.join(col).strip() for col in pivot_df.columns.values]\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    insurance_data = insurance_data.reset_index().rename(columns={'index': 'Insurance_Row_Index'})\n",
    "    final_result = insurance_data.merge(pivot_df, on='Insurance_Row_Index', how='left')\n",
    "\n",
    "    value_cols = [col for col in final_result.columns if col.startswith(('Claim_Number_', 'Payed_Amount_', 'Last_Pending_Amount_', 'Incurred_'))]\n",
    "    final_result[value_cols] = final_result[value_cols].fillna(0)\n",
    "\n",
    "    final_result['Total_Claim_Count'] = final_result.filter(like='Claim_Number_').sum(axis=1)\n",
    "    final_result['Total_Payed_Amount'] = final_result.filter(like='Payed_Amount_').sum(axis=1)\n",
    "    final_result['Total_Pending_Amount'] = final_result.filter(like='Last_Pending_Amount_').sum(axis=1)\n",
    "    final_result['Total_Incurred_Amount'] = final_result.filter(like='Incurred_').sum(axis=1)\n",
    "\n",
    "    final_result.drop(columns=['Insurance_Row_Index', 'Key', 'Cliente'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Unit Count per Policy-Year\n",
    "    print(\"ðŸ”¢ Calculating Unit_Count_Per_Policy_Year...\")\n",
    "    final_result['Start_Year'] = pd.to_datetime(final_result['Start_Date']).dt.year\n",
    "    unit_counts = final_result.groupby(['Policy', 'Start_Year'])['Unit'].nunique().reset_index()\n",
    "    unit_counts = unit_counts.rename(columns={'Unit': 'Unit_Count_Per_Policy_Year'})\n",
    "    final_result = final_result.merge(unit_counts, on=['Policy', 'Start_Year'], how='left')\n",
    "\n",
    "    # Historical metrics\n",
    "    print(\"ðŸ“Š Calculating historical metrics...\")\n",
    "    final_result['PU_Key'] = final_result['Policy'] + '_' + final_result['Unit']\n",
    "    with_claims = final_result[(final_result['Total_Claim_Count'] > 0) | (final_result['Total_Incurred_Amount'] > 0)]\n",
    "    claim_count_results = []\n",
    "\n",
    "    grouped = with_claims.groupby('PU_Key')\n",
    "    for key, group in tqdm(grouped, desc=\"Historical calculations\", total=len(grouped)):\n",
    "        group = group.sort_values('Start_Date')\n",
    "        hist_claims = []\n",
    "        hist_ratios = []\n",
    "        for i in range(len(group)):\n",
    "            past = group[group['Start_Date'] < group.iloc[i]['Start_Date']]\n",
    "            hist_claims.append(past['Total_Claim_Count'].sum())\n",
    "            premium = past['PrimaSuscrita'].sum()\n",
    "            incurred = past['Total_Incurred_Amount'].sum()\n",
    "            hist_ratios.append(incurred / premium if premium else None)\n",
    "        group['Historical_Claim_Count'] = hist_claims\n",
    "        group['Historical_Loss_Ratio'] = hist_ratios\n",
    "        claim_count_results.append(group)\n",
    "\n",
    "    enriched = pd.concat(claim_count_results, ignore_index=True)\n",
    "    enriched['Current_Loss_Ratio'] = enriched['Total_Incurred_Amount'] / enriched['PrimaSuscrita']\n",
    "\n",
    "    final_result = final_result.drop(columns=['PU_Key'], errors='ignore')\n",
    "    final_result = final_result.merge(\n",
    "        enriched[['Policy', 'Unit', 'Start_Date', 'Historical_Claim_Count', 'Historical_Loss_Ratio', 'Current_Loss_Ratio']],\n",
    "        on=['Policy', 'Unit', 'Start_Date'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    print(\"ðŸ§¼ Final formatting for export...\")\n",
    "    for col in tqdm(final_result.columns, desc=\"Final format\"):\n",
    "        if final_result[col].dtype == \"object\":\n",
    "            final_result[col] = final_result[col].fillna(\"\").astype(str)\n",
    "        elif pd.api.types.is_numeric_dtype(final_result[col]):\n",
    "            final_result[col] = pd.to_numeric(final_result[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Export\n",
    "    print(\"ðŸ“… Exporting final results...\")\n",
    "    final_result.to_csv('Insurance_1to1_Merged_With_Loss_Ratio.csv', index=False, encoding='utf-8-sig')\n",
    "    final_result.to_parquet(\"Insurance_1to1_Merged_With_Loss_Ratio.parquet\", index=False)\n",
    "\n",
    "    # Optional: Remove accents\n",
    "    def remove_accents(text):\n",
    "        if isinstance(text, str):\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "            text = text.replace('Ã±', 'n').replace('Ã‘', 'N')\n",
    "        return text\n",
    "\n",
    "    print(\"ðŸŒ Removing accents from string columns...\")\n",
    "    for col in tqdm(final_result.columns, desc=\"Removing accents\"):\n",
    "        if final_result[col].dtype == \"object\":\n",
    "            final_result[col] = final_result[col].apply(remove_accents)\n",
    "\n",
    "    final_result.to_csv('Insurance_1to1_Merged_With_Loss_Ratio_CleanText.csv', index=False, encoding='utf-8-sig')\n",
    "else:\n",
    "    final_result = pd.DataFrame()\n",
    "    print(\"âš ï¸ No matched claims found.\")\n",
    "\n",
    "# Export unmatched claims\n",
    "unmatched_all = unmatched_claims + [\n",
    "    {\n",
    "        'Policy': row['Policy'],\n",
    "        'Unit': row['Unit'],\n",
    "        'Start_Date': row['Start_Date'],\n",
    "        'End_Date': row['End_Date'],\n",
    "        'Reason': 'Policy-Unit not found in claims data'\n",
    "    }\n",
    "    for _, row in non_matching_rows.iterrows()\n",
    "]\n",
    "if unmatched_all:\n",
    "    unmatched_df = pd.DataFrame(unmatched_all)\n",
    "    unmatched_df.to_csv('Unmatched_Claims_Final.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"âš ï¸ Exported {len(unmatched_df)} unmatched entries.\")\n",
    "else:\n",
    "    print(\"âœ… All insurance rows matched successfully.\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nðŸ’° Total Incurred Matched: {final_result['Total_Incurred_Amount'].sum():,.2f}\")\n",
    "print(f\"ðŸ•’ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
